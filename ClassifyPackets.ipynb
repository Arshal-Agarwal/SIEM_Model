{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "394583e6-4448-475d-a344-13c55e55c14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\ajaga\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
      "Predicted Packet Class: DoS_Slowloris\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(\"network_packet_classifier_v2.h5\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "malicious_packet = np.array([\n",
    "    -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, \n",
    "    -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, \n",
    "    -1000, -1000\n",
    "]).reshape(1, -1)\n",
    "\n",
    "\n",
    "new_packet_scaled = scaler.transform(malicious_packet)\n",
    "\n",
    "prediction = model.predict(new_packet_scaled)\n",
    "predicted_label = np.argmax(prediction)  \n",
    "\n",
    "predicted_class = label_encoder.inverse_transform([predicted_label])[0]\n",
    "print(f\"Predicted Packet Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3ff0694-4d6b-4268-acbf-ee67e9b5c55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Packet 1 classified as: Benign\n",
      "Packet 2 classified as: Benign\n",
      "Packet 3 classified as: Benign\n",
      "Packet 4 classified as: Benign\n",
      "Packet 5 classified as: Benign\n",
      "Packet 6 classified as: Benign\n",
      "Packet 7 classified as: Benign\n",
      "Packet 8 classified as: Benign\n",
      "Packet 9 classified as: Benign\n",
      "Packet 10 classified as: Benign\n",
      "Packet 11 classified as: Benign\n",
      "Packet 12 classified as: Benign\n",
      "Packet 13 classified as: Benign\n",
      "Packet 14 classified as: Benign\n",
      "Packet 15 classified as: Benign\n",
      "Packet 16 classified as: Benign\n",
      "Packet 17 classified as: Benign\n",
      "Packet 18 classified as: Benign\n",
      "Packet 19 classified as: Benign\n",
      "Packet 20 classified as: Benign\n",
      "Packet 21 classified as: Benign\n",
      "Packet 22 classified as: Benign\n",
      "Packet 23 classified as: Benign\n",
      "Packet 24 classified as: Benign\n",
      "Packet 25 classified as: Benign\n",
      "Packet 26 classified as: Benign\n",
      "Packet 27 classified as: Benign\n",
      "Packet 28 classified as: Benign\n",
      "Packet 29 classified as: Benign\n",
      "Packet 30 classified as: Benign\n",
      "Packet 31 classified as: Benign\n",
      "Packet 32 classified as: Benign\n",
      "Packet 33 classified as: Benign\n",
      "Packet 34 classified as: Benign\n",
      "Packet 35 classified as: Benign\n",
      "Packet 36 classified as: Benign\n",
      "Packet 37 classified as: Benign\n",
      "Packet 38 classified as: Benign\n",
      "Packet 39 classified as: Benign\n",
      "Packet 40 classified as: Benign\n",
      "Packet 41 classified as: Benign\n",
      "Packet 42 classified as: Benign\n",
      "Packet 43 classified as: Benign\n",
      "Packet 44 classified as: Benign\n",
      "Packet 45 classified as: Benign\n",
      "Packet 46 classified as: Benign\n",
      "Packet 47 classified as: Benign\n",
      "Packet 48 classified as: Benign\n",
      "Packet 49 classified as: Benign\n",
      "Packet 50 classified as: Benign\n",
      "Packet 51 classified as: Benign\n",
      "Packet 52 classified as: Benign\n",
      "Packet 53 classified as: Benign\n",
      "Packet 54 classified as: Benign\n",
      "Packet 55 classified as: Benign\n",
      "Packet 56 classified as: Benign\n",
      "Packet 57 classified as: Benign\n",
      "Packet 58 classified as: Benign\n",
      "Packet 59 classified as: Benign\n",
      "Packet 60 classified as: Benign\n",
      "Packet 61 classified as: Benign\n",
      "Packet 62 classified as: Benign\n",
      "Packet 63 classified as: Benign\n",
      "Packet 64 classified as: Benign\n",
      "Packet 65 classified as: Benign\n",
      "Packet 66 classified as: Benign\n",
      "Packet 67 classified as: Benign\n",
      "Packet 68 classified as: Benign\n",
      "Packet 69 classified as: Benign\n",
      "Packet 70 classified as: Benign\n",
      "Packet 71 classified as: Benign\n",
      "Packet 72 classified as: Benign\n",
      "Packet 73 classified as: Benign\n",
      "Packet 74 classified as: Benign\n",
      "Packet 75 classified as: Benign\n",
      "Packet 76 classified as: Benign\n",
      "Packet 77 classified as: Benign\n",
      "Packet 78 classified as: Benign\n",
      "Packet 79 classified as: Benign\n",
      "Packet 80 classified as: Benign\n",
      "Packet 81 classified as: Benign\n",
      "Packet 82 classified as: Benign\n",
      "Packet 83 classified as: Benign\n",
      "Packet 84 classified as: Benign\n",
      "Packet 85 classified as: Benign\n",
      "Packet 86 classified as: Benign\n",
      "Packet 87 classified as: Benign\n",
      "Packet 88 classified as: Benign\n",
      "Packet 89 classified as: Benign\n",
      "Packet 90 classified as: Benign\n",
      "Packet 91 classified as: Benign\n",
      "Packet 92 classified as: Benign\n",
      "Packet 93 classified as: Benign\n",
      "Packet 94 classified as: Benign\n",
      "Packet 95 classified as: Benign\n",
      "Packet 96 classified as: Benign\n",
      "Packet 97 classified as: Benign\n",
      "Packet 98 classified as: Benign\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"PACKETS_TRANSFORMED.json\", \"r\") as file:\n",
    "    packet_data = json.load(file)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_packets = pd.DataFrame(packet_data)\n",
    "\n",
    "# Load the saved scaler and label encoder\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "# Select the same feature columns as during training\n",
    "features = [\n",
    "    \"duration\", \"packets_count\", \"fwd_packets_count\", \"bwd_packets_count\",\n",
    "    \"total_payload_bytes\", \"fwd_total_payload_bytes\", \"bwd_total_payload_bytes\",\n",
    "    \"payload_bytes_max\", \"payload_bytes_min\", \"payload_bytes_mean\",\n",
    "    \"bytes_rate\", \"packets_rate\",\n",
    "    \"fwd_total_header_bytes\", \"bwd_total_header_bytes\",\n",
    "    \"avg_segment_size\", \"fwd_avg_segment_size\", \"bwd_avg_segment_size\",\n",
    "    \"fwd_init_win_bytes\", \"bwd_init_win_bytes\",\n",
    "    \"active_mean\", \"idle_mean\", \"down_up_rate\"\n",
    "]\n",
    "\n",
    "# Ensure all columns exist\n",
    "df_packets = df_packets[features]\n",
    "\n",
    "# Handle missing values (if any)\n",
    "df_packets.fillna(df_packets.mean(), inplace=True)\n",
    "\n",
    "# Normalize the features using the same scaler\n",
    "X_packets = scaler.transform(df_packets)\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"network_packet_classifier_v2.h5\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_packets)\n",
    "predicted_labels = np.argmax(predictions, axis=1)  # Get the label index\n",
    "\n",
    "# Convert numeric labels back to class names\n",
    "predicted_classes = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "# Display results\n",
    "for i, packet in enumerate(packet_data):\n",
    "    print(f\"Packet {i+1} classified as: {predicted_classes[i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
